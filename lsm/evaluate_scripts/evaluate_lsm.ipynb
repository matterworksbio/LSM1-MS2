{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/miniconda3/envs/mamba/envs/lsm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../lsm/\")\n",
    "from msdatasets import MSDataset\n",
    "from pretrain_MAE import SSModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "path = '' # define path to data\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/miniconda3/envs/mamba/envs/lsm/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "lsm_checkpoint = '' # define checkpoint path \n",
    "model = SSModel.load_from_checkpoint(f'{path}/trained_models/{lsm_checkpoint}').cuda().eval()\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is (12274, 5) dimensions\n",
      "Data is (1000, 5) dimensions\n",
      "Data is (464, 5) dimensions\n"
     ]
    }
   ],
   "source": [
    "test_unknown = MSDataset(f'{path}/datasets/test/test.zarr/')\n",
    "test_known = MSDataset(f'{path}/datasets/test/disjoint_test.zarr/')\n",
    "test_casmi = MSDataset(f'{path}/datasets/test/casmi.zarr/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_dataloader = DataLoader(test_unknown, batch_size=256, shuffle=False, num_workers=0)\n",
    "known_dataloader = DataLoader(test_known, batch_size=256, shuffle=False, num_workers=0)\n",
    "casmi_dataloader = DataLoader(test_casmi, batch_size=256, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, dataloader, dataset):\n",
    "    pl.seed_everything(42)\n",
    "    \n",
    "    #unknown predictions\n",
    "    unknown_gt_mz = np.zeros((len(dataset), 64))\n",
    "    unknown_gt_inty = np.zeros((len(dataset), 64))\n",
    "    preds_mz = np.zeros((len(dataset), 64))\n",
    "    preds_inty = np.zeros((len(dataset), 64))\n",
    "\n",
    "    masked_inty_preds = []\n",
    "    masked_inty_gt = []\n",
    "    masked_mz_preds = []\n",
    "    masked_mz_gt = []\n",
    "\n",
    "    j = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        mz, inty, precursormz, pad_idx = batch['mz'], batch['inty'], batch['precursormz'], batch['pad_idx']\n",
    "        mz, inty, precursormz, pad_idx = mz.to(device), inty.to(device), precursormz.to(device), pad_idx.to(device)\n",
    "        \n",
    "        mz1_logits, mz2_logits, inty_logits, mask = model(precursormz, mz, inty)\n",
    "        mask = mask.detach().cpu().numpy()\n",
    "        mz1_logits = mz1_logits.detach().cpu().numpy()\n",
    "        mz2_logits = mz2_logits.detach().cpu().numpy()\n",
    "        inty_logits = inty_logits.detach().cpu().numpy()\n",
    "        mz = mz.detach().cpu().numpy()\n",
    "        inty = inty.detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "        # convert logits to classifications\n",
    "        mz1 = np.argmax(mz1_logits, axis=-1)\n",
    "        mz2 = np.argmax(mz2_logits, axis=-1)\n",
    "        inty_logits = np.argmax(inty_logits, axis=-1)    \n",
    "        pred_mz = mz1 + mz2/1000\n",
    "        pred_inty = inty_logits\n",
    "        # add to predictions list \n",
    "        for i in range(len(pad_idx)):      \n",
    "            unknown_gt_mz[i+j, :pad_idx[i]] = mz[i, :pad_idx[i]]\n",
    "            unknown_gt_inty[i+j, :pad_idx[i]] = inty[i, :pad_idx[i]]\n",
    "            preds_mz[i+j, :pad_idx[i]] = pred_mz[i, :pad_idx[i]]\n",
    "            preds_inty[i+j, :pad_idx[i]] = pred_inty[i, :pad_idx[i]]\n",
    "\n",
    "\n",
    "            unpadded_pred_mz = pred_mz[i, :pad_idx[i]]\n",
    "            unpadded_pred_inty = pred_inty[i, :pad_idx[i]]\n",
    "            unpadded_gt_mz = mz[i, :pad_idx[i]]\n",
    "            unpadded_gt_inty = inty[i, :pad_idx[i]]\n",
    "            unpadded_mask = mask[i, :pad_idx[i]]\n",
    "            \n",
    "            # add masked values to list\n",
    "            masked_mz_preds.append(unpadded_pred_mz[unpadded_mask])\n",
    "            masked_mz_gt.append(unpadded_gt_mz[unpadded_mask])\n",
    "            masked_inty_preds.append(unpadded_pred_inty[unpadded_mask])\n",
    "            masked_inty_gt.append(unpadded_gt_inty[unpadded_mask])\n",
    "\n",
    "        j += len(pred_inty)\n",
    "\n",
    "    masked_mz_preds = np.concatenate(np.array(masked_mz_preds).flatten())\n",
    "    masked_mz_gt = np.concatenate(np.array(masked_mz_gt).flatten())\n",
    "    masked_inty_preds = np.concatenate(np.array(masked_inty_preds).flatten())\n",
    "    masked_inty_gt = np.concatenate(np.array(masked_inty_gt).flatten())\n",
    "    \n",
    "    return unknown_gt_mz, unknown_gt_inty, preds_mz, preds_inty, masked_mz_preds, masked_mz_gt, masked_inty_preds, masked_inty_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "100%|██████████| 48/48 [00:15<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.76453322136245 1.7797870946598928\n",
      "120.4629590256052 6.758868442819854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_585494/4051790470.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_mz_preds = np.concatenate(np.array(masked_mz_preds).flatten())\n",
      "/tmp/ipykernel_585494/4051790470.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_mz_gt = np.concatenate(np.array(masked_mz_gt).flatten())\n",
      "/tmp/ipykernel_585494/4051790470.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_inty_preds = np.concatenate(np.array(masked_inty_preds).flatten())\n",
      "/tmp/ipykernel_585494/4051790470.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_inty_gt = np.concatenate(np.array(masked_inty_gt).flatten())\n"
     ]
    }
   ],
   "source": [
    "unknown_gt_mz, unknown_gt_inty, preds_mz, preds_inty, masked_mz_preds, masked_mz_gt, masked_inty_preds, masked_inty_gt = get_preds(model, unknown_dataloader, test_unknown)\n",
    "\n",
    "#get number of non-zero peaks in unknown_gt\n",
    "non_zero = np.sum(np.count_nonzero(unknown_gt_inty, axis=-1))\n",
    "\n",
    "#calculate the MAE of the model for both mz and inty\n",
    "mae_inty = np.mean(np.abs(preds_inty - unknown_gt_inty)) / (non_zero/(unknown_gt_mz.shape[0] * unknown_gt_mz.shape[1]))\n",
    "mae_mz  = np.mean(np.abs(preds_mz - unknown_gt_mz)) / (non_zero/(unknown_gt_mz.shape[0] * unknown_gt_mz.shape[1]))\n",
    "print(mae_inty, mae_mz)\n",
    "\n",
    "#calculate the MAE of the model for both mz and inty on masked data\n",
    "mae_inty_masked = np.mean(np.abs(masked_inty_preds - masked_inty_gt))\n",
    "mae_mz_masked  = np.mean(np.abs(masked_mz_preds - masked_mz_gt))\n",
    "print(mae_inty_masked, mae_mz_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12274, 64)\n",
      "(12274, 64)\n",
      "(12274, 64)\n",
      "(12274, 64)\n",
      "(65846, 1)\n",
      "(65846, 1)\n",
      "(65846, 1)\n",
      "(65846, 1)\n"
     ]
    }
   ],
   "source": [
    "# save these to pickles\n",
    "inty_gt = pd.DataFrame(unknown_gt_inty)\n",
    "inty_preds = pd.DataFrame(preds_inty)\n",
    "mz_gt = pd.DataFrame(unknown_gt_mz)\n",
    "mz_preds = pd.DataFrame(preds_mz)\n",
    "masked_inty_gt = pd.DataFrame(masked_inty_gt)\n",
    "masked_inty_preds = pd.DataFrame(masked_inty_preds)\n",
    "masked_mz_gt = pd.DataFrame(masked_mz_gt)\n",
    "masked_mz_preds = pd.DataFrame(masked_mz_preds)\n",
    "\n",
    "# print the shapes of all of the dataframes\n",
    "print(inty_gt.shape)\n",
    "print(inty_preds.shape)\n",
    "print(mz_gt.shape)\n",
    "print(mz_preds.shape)\n",
    "print(masked_inty_gt.shape)\n",
    "print(masked_inty_preds.shape)\n",
    "print(masked_mz_gt.shape)\n",
    "print(masked_mz_preds.shape)\n",
    "\n",
    "os.makedirs('../../results/pretrain/', exist_ok=True)\n",
    "\n",
    "inty_gt.to_pickle(f'../../results/pretrain/unknown_inty_gt.pkl')\n",
    "inty_preds.to_pickle(f'../../results/pretrain/unknown_inty_preds.pkl')\n",
    "mz_gt.to_pickle(f'../../results/pretrain/unknown_mz_gt.pkl')\n",
    "mz_preds.to_pickle(f'../../results/pretrain/unknown_mz_preds.pkl')\n",
    "masked_inty_gt.to_pickle(f'../../results/pretrain/unknown_masked_inty_gt.pkl')\n",
    "masked_inty_preds.to_pickle(f'../../results/pretrain/unknown_masked_inty_preds.pkl')\n",
    "masked_mz_gt.to_pickle(f'../../results/pretrain/unknown_masked_mz_gt.pkl')\n",
    "masked_mz_preds.to_pickle(f'../../results/pretrain/unknown_masked_mz_preds.pkl')\n",
    "\n",
    "# make small df with mae values\n",
    "mae_df = pd.DataFrame({'MAE_inty': [mae_inty], 'MAE_mz': [mae_mz], 'MAE_inty_masked': [mae_inty_masked], 'MAE_mz_masked': [mae_mz_masked]})\n",
    "mae_df.to_csv(f'../../results/pretrain/unknown_mae_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11451\n",
      "30.49017553052135 1.3373643115507274\n",
      "122.56621499548329 5.49030040877014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_134857/4084876854.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_mz_preds = np.concatenate(np.array(masked_mz_preds).flatten())\n",
      "/tmp/ipykernel_134857/4084876854.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_mz_gt = np.concatenate(np.array(masked_mz_gt).flatten())\n",
      "/tmp/ipykernel_134857/4084876854.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_inty_preds = np.concatenate(np.array(masked_inty_preds).flatten())\n",
      "/tmp/ipykernel_134857/4084876854.py:61: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_inty_gt = np.concatenate(np.array(masked_inty_gt).flatten())\n"
     ]
    }
   ],
   "source": [
    "known_gt_mz, known_gt_inty, preds_mz, preds_inty, masked_mz_preds, masked_mz_gt, masked_inty_preds, masked_inty_gt = get_preds(model, known_dataloader, test_known)\n",
    "\n",
    "#get number of non-zero peaks in unknown_gt\n",
    "non_zero = np.sum(np.count_nonzero(known_gt_inty, axis=-1))\n",
    "print(non_zero)\n",
    "\n",
    "#calculate the MAE of the model for both mz and inty\n",
    "mae_inty = np.mean(np.abs(preds_inty - known_gt_inty)) / (non_zero/(known_gt_mz.shape[0] * known_gt_mz.shape[1]))\n",
    "mae_mz  = np.mean(np.abs(preds_mz - known_gt_mz)) / (non_zero/(known_gt_mz.shape[0] * known_gt_mz.shape[1]))\n",
    "print(mae_inty, mae_mz)\n",
    "\n",
    "#calculate the MAE of the model for both mz and inty on masked data\n",
    "mae_inty_masked = np.mean(np.abs(masked_inty_preds - masked_inty_gt))\n",
    "mae_mz_masked  = np.mean(np.abs(masked_mz_preds - masked_mz_gt))\n",
    "print(mae_inty_masked, mae_mz_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 64)\n",
      "(1000, 64)\n",
      "(1000, 64)\n",
      "(1000, 64)\n",
      "(5535, 1)\n",
      "(5535, 1)\n",
      "(5535, 1)\n",
      "(5535, 1)\n"
     ]
    }
   ],
   "source": [
    "# save these to pickles\n",
    "inty_gt = pd.DataFrame(known_gt_inty)\n",
    "inty_preds = pd.DataFrame(preds_inty)\n",
    "mz_gt = pd.DataFrame(known_gt_mz)\n",
    "mz_preds = pd.DataFrame(preds_mz)\n",
    "masked_inty_gt = pd.DataFrame(masked_inty_gt)\n",
    "masked_inty_preds = pd.DataFrame(masked_inty_preds)\n",
    "masked_mz_gt = pd.DataFrame(masked_mz_gt)\n",
    "masked_mz_preds = pd.DataFrame(masked_mz_preds)\n",
    "\n",
    "# print the shapes of all of the dataframes\n",
    "print(inty_gt.shape)\n",
    "print(inty_preds.shape)\n",
    "print(mz_gt.shape)\n",
    "print(mz_preds.shape)\n",
    "print(masked_inty_gt.shape)\n",
    "print(masked_inty_preds.shape)\n",
    "print(masked_mz_gt.shape)\n",
    "print(masked_mz_preds.shape)\n",
    "\n",
    "os.makedirs('../../results/pretrain/', exist_ok=True)\n",
    "\n",
    "inty_gt.to_pickle(f'../../results/pretrain/known_inty_gt.pkl')\n",
    "inty_preds.to_pickle(f'../../results/pretrain/known_inty_preds.pkl')\n",
    "mz_gt.to_pickle(f'../../results/pretrain/known_mz_gt.pkl')\n",
    "mz_preds.to_pickle(f'../../results/pretrain/known_mz_preds.pkl')\n",
    "masked_inty_gt.to_pickle(f'../../results/pretrain/known_masked_inty_gt.pkl')\n",
    "masked_inty_preds.to_pickle(f'../../results/pretrain/known_masked_inty_preds.pkl')\n",
    "masked_mz_gt.to_pickle(f'../../results/pretrain/known_masked_mz_gt.pkl')\n",
    "masked_mz_preds.to_pickle(f'../../results/pretrain/known_masked_mz_preds.pkl')\n",
    "\n",
    "# make small df with mae values\n",
    "mae_df = pd.DataFrame({'MAE_inty': [mae_inty], 'MAE_mz': [mae_mz], 'MAE_inty_masked': [mae_inty_masked], 'MAE_mz_masked': [mae_mz_masked]})\n",
    "mae_df.to_csv(f'../../results/pretrain/known_mae_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10346\n",
      "33.17910303498937 2.012001481326664\n",
      "122.69696176008381 7.974461207849934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_134857/4084876854.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_mz_preds = np.concatenate(np.array(masked_mz_preds).flatten())\n",
      "/tmp/ipykernel_134857/4084876854.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_mz_gt = np.concatenate(np.array(masked_mz_gt).flatten())\n",
      "/tmp/ipykernel_134857/4084876854.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_inty_preds = np.concatenate(np.array(masked_inty_preds).flatten())\n",
      "/tmp/ipykernel_134857/4084876854.py:61: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  masked_inty_gt = np.concatenate(np.array(masked_inty_gt).flatten())\n"
     ]
    }
   ],
   "source": [
    "casmi_gt_mz, casmi_gt_inty, preds_mz, preds_inty, masked_mz_preds, masked_mz_gt, masked_inty_preds, masked_inty_gt = get_preds(model, casmi_dataloader, test_casmi)\n",
    "\n",
    "#get number of non-zero peaks in unknown_gt\n",
    "non_zero = np.sum(np.count_nonzero(casmi_gt_inty, axis=-1))\n",
    "print(non_zero)\n",
    "\n",
    "#calculate the MAE of the model for both mz and inty\n",
    "mae_inty = np.mean(np.abs(preds_inty - casmi_gt_inty)) / (non_zero/(casmi_gt_mz.shape[0] * casmi_gt_mz.shape[1]))\n",
    "mae_mz  = np.mean(np.abs(preds_mz - casmi_gt_mz)) / (non_zero/(casmi_gt_mz.shape[0] * casmi_gt_mz.shape[1]))\n",
    "print(mae_inty, mae_mz)\n",
    "\n",
    "#calculate the MAE of the model for both mz and inty on masked data\n",
    "mae_inty_masked = np.mean(np.abs(masked_inty_preds - masked_inty_gt))\n",
    "mae_mz_masked  = np.mean(np.abs(masked_mz_preds - masked_mz_gt))\n",
    "print(mae_inty_masked, mae_mz_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464, 64)\n",
      "(464, 64)\n",
      "(464, 64)\n",
      "(464, 64)\n",
      "(3818, 1)\n",
      "(3818, 1)\n",
      "(3818, 1)\n",
      "(3818, 1)\n"
     ]
    }
   ],
   "source": [
    "# save these to pickles\n",
    "inty_gt = pd.DataFrame(casmi_gt_inty)\n",
    "inty_preds = pd.DataFrame(preds_inty)\n",
    "mz_gt = pd.DataFrame(casmi_gt_mz)\n",
    "mz_preds = pd.DataFrame(preds_mz)\n",
    "masked_inty_gt = pd.DataFrame(masked_inty_gt)\n",
    "masked_inty_preds = pd.DataFrame(masked_inty_preds)\n",
    "masked_mz_gt = pd.DataFrame(masked_mz_gt)\n",
    "masked_mz_preds = pd.DataFrame(masked_mz_preds)\n",
    "\n",
    "# print the shapes of all of the dataframes\n",
    "print(inty_gt.shape)\n",
    "print(inty_preds.shape)\n",
    "print(mz_gt.shape)\n",
    "print(mz_preds.shape)\n",
    "print(masked_inty_gt.shape)\n",
    "print(masked_inty_preds.shape)\n",
    "print(masked_mz_gt.shape)\n",
    "print(masked_mz_preds.shape)\n",
    "\n",
    "os.makedirs('../../results/pretrain/', exist_ok=True)\n",
    "\n",
    "inty_gt.to_pickle(f'../../results/pretrain/casmi_inty_gt.pkl')\n",
    "inty_preds.to_pickle(f'../../results/pretrain/casmi_inty_preds.pkl')\n",
    "mz_gt.to_pickle(f'../../results/pretrain/casmi_mz_gt.pkl')\n",
    "mz_preds.to_pickle(f'../../results/pretrain/casmi_mz_preds.pkl')\n",
    "masked_inty_gt.to_pickle(f'../../results/pretrain/casmi_masked_inty_gt.pkl')\n",
    "masked_inty_preds.to_pickle(f'../../results/pretrain/casmi_masked_inty_preds.pkl')\n",
    "masked_mz_gt.to_pickle(f'../../results/pretrain/casmi_masked_mz_gt.pkl')\n",
    "masked_mz_preds.to_pickle(f'../../results/pretrain/casmi_masked_mz_preds.pkl')\n",
    "\n",
    "# make small df with mae values\n",
    "mae_df = pd.DataFrame({'MAE_inty': [mae_inty], 'MAE_mz': [mae_mz], 'MAE_inty_masked': [mae_inty_masked], 'MAE_mz_masked': [mae_mz_masked]})\n",
    "mae_df.to_csv(f'../../results/pretrain/casmi_mae_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
