{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from utils import results_to_df, evaluate_dataset\n",
    "# Add your desired directory to PYTHONPATH\n",
    "sys.path.append(\"../../lsm/\")\n",
    "\n",
    "from train_property import Finetune_SSModel\n",
    "from msdatasets import MSDataset\n",
    "\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "all_descriptors = {name: func for name, func in Descriptors.descList}\n",
    "\n",
    "feature_names = list(all_descriptors.keys())\n",
    "path = \"\" # path to data here\n",
    "norm_values = pd.read_csv(f'{path}/datasets/processed_data/norm_values.csv')\n",
    "mini = np.array(norm_values.iloc[0, :])\n",
    "maxi = np.array(norm_values.iloc[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is (12274, 5) dimensions\n",
      "Data is (1000, 5) dimensions\n",
      "Data is (464, 5) dimensions\n"
     ]
    }
   ],
   "source": [
    "test_set_disjoint = MSDataset(f'{path}/datasets/test/test.zarr', mode='property', train_minmax_path = f'{path}/datasets/processed_data/norm_values.csv')\n",
    "test_set_overlap = MSDataset(f'{path}/datasets/test/disjoint_test.zarr', mode='property', train_minmax_path = f'{path}/datasets/processed_data/norm_values.csv')\n",
    "test_set_casmi = MSDataset(f'{path}/datasets/test/casmi.zarr', mode='property', train_minmax_path = f'{path}/datasets/processed_data/norm_values.csv')\n",
    "            \n",
    "loader1 =  DataLoader(\n",
    "    test_set_disjoint,\n",
    "    batch_size= 64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "loader2 = DataLoader(\n",
    "    test_set_overlap,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "loader3 = DataLoader(\n",
    "    test_set_casmi,\n",
    "    batch_size = 64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''\n",
    "model = Finetune_SSModel.load_from_checkpoint(f'{path}/trained_models/{model_name}_best.ckpt', map_location='cuda:0').cuda().eval()\n",
    "\n",
    "#make results directory\n",
    "os.makedirs(f'../../results/{model_name}', exist_ok=True)\n",
    "results_path = f'../../results/{model_name}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on \"unknown\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2, mae, smape, GT_feats, Y_feats, wmape, f1, accuracy, precision, recall = evaluate_dataset(loader1, model)\n",
    "df, df_ms2, df_categorical = results_to_df(feature_names, mae, r2, norm_values, smape, wmape, f1, accuracy, precision, recall)\n",
    "\n",
    "#write results to results path:\n",
    "GT_feats = pd.DataFrame(GT_feats, columns=feature_names)\n",
    "Y_feats = pd.DataFrame(Y_feats, columns=feature_names)\n",
    "#make \"unknown data\" subdirectory\n",
    "os.makedirs(f'{results_path}unknown_data', exist_ok=True)\n",
    "GT_feats.to_csv(f'{results_path}unknown_data/GT_feats.csv')\n",
    "Y_feats.to_csv(f'{results_path}unknown_data/Y_feats.csv')\n",
    "df.to_csv(f'{results_path}unknown_data/results.csv')\n",
    "df_ms2.to_csv(f'{results_path}unknown_data/results_ms2.csv')\n",
    "df_categorical.to_csv(f'{results_path}unknown_data/results_categorical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on \"known\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 20.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -16931016.186098903\n",
      "mae: 8.249730707663247\n",
      "smape: 0.057887665927410126\n",
      "wmape: 34567.78515625\n",
      "accuracy: 0.01160287081339713\n",
      "precision: 0.01160287081339713\n",
      "recall: 0.01160287081339713\n",
      "f1: 0.011602867918663249\n"
     ]
    }
   ],
   "source": [
    "r2, mae, smape, GT_feats, Y_feats, wmape, f1, accuracy, precision, recall = evaluate_dataset(loader2, model)\n",
    "df, df_ms2, df_categorical = results_to_df(feature_names, mae, r2, norm_values, smape, wmape, f1, accuracy, precision, recall)\n",
    "\n",
    "#write results to results path:\n",
    "GT_feats = pd.DataFrame(GT_feats, columns=feature_names)\n",
    "Y_feats = pd.DataFrame(Y_feats, columns=feature_names)\n",
    "#make \"unknown data\" subdirectory\n",
    "os.makedirs(f'{results_path}known_data', exist_ok=True)\n",
    "GT_feats.to_csv(f'{results_path}known_data/GT_feats.csv')\n",
    "Y_feats.to_csv(f'{results_path}known_data/Y_feats.csv')\n",
    "df.to_csv(f'{results_path}known_data/results.csv')\n",
    "df_ms2.to_csv(f'{results_path}known_data/results_ms2.csv')\n",
    "df_categorical.to_csv(f'{results_path}known_data/results_categorical.csv')\n",
    "# df_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on CASMI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -16936397.7608993\n",
      "mae: 9.165955031469208\n",
      "smape: 0.06174078956246376\n",
      "wmape: 41773.7421875\n",
      "accuracy: 0.008393829401088928\n",
      "precision: 0.008393829401088928\n",
      "recall: 0.008393829401088928\n",
      "f1: 0.008393826841282783\n"
     ]
    }
   ],
   "source": [
    "r2, mae, smape, GT_feats, Y_feats, wmape, f1, accuracy, precision, recall = evaluate_dataset(loader3, model)\n",
    "df, df_ms2, df_categorical = results_to_df(feature_names, mae, r2, norm_values, smape, wmape, f1, accuracy, precision, recall)\n",
    "\n",
    "#write results to results path:\n",
    "GT_feats = pd.DataFrame(GT_feats, columns=feature_names)\n",
    "Y_feats = pd.DataFrame(Y_feats, columns=feature_names)\n",
    "#make \"unknown data\" subdirectory\n",
    "os.makedirs(f'{results_path}casmi_data', exist_ok=True)\n",
    "GT_feats.to_csv(f'{results_path}casmi_data/GT_feats.csv')\n",
    "Y_feats.to_csv(f'{results_path}casmi_data/Y_feats.csv')\n",
    "df.to_csv(f'{results_path}casmi_data/results.csv')\n",
    "df_ms2.to_csv(f'{results_path}casmi_data/results_ms2.csv')\n",
    "df_categorical.to_csv(f'{results_path}casmi_data/results_categorical.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on modified cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test was produced with 'generate_mod_cosine_scores.py' in preprocess_ns2 folder\n",
    "df_test = pd.read_pickle(f'{path}/datasets/processed_data/test_modified_cosine_results.pkl')\n",
    "df_gt_test = pd.read_pickle(f'{path}/datasets/processed_data/test_df.pkl')\n",
    "df_train = pd.read_pickle(f'{path}/datasets/processed_data/train_df.pkl')\n",
    "results_path = f'../../results/cosine_similarity/'\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each value in df_test['Train_SMILES'], retrieve the last 209 values in df_train (property predictions), and use these as the property predictions for df_test\n",
    "def get_last_209_predictions(smiles):\n",
    "    try: \n",
    "        return df_train[df_train['smiles']==smiles].iloc[0, -209:]\n",
    "    except:\n",
    "        return np.full(209, np.nan)\n",
    "feats = df_test['Train_SMILES'].apply(lambda x: get_last_209_predictions(x))\n",
    "df_test = pd.concat([df_test, feats], axis=1)\n",
    "\n",
    "cos_feats = df_test.iloc[:, -209:]\n",
    "gt_feats = df_gt_test.iloc[:, -209:]\n",
    "\n",
    "#get columnwise r2\n",
    "epsilon = 1e-8\n",
    "Y_feats = cos_feats.values\n",
    "GT_feats = gt_feats.values\n",
    "# Calculating R^2\n",
    "numerator = np.sum((GT_feats - Y_feats) ** 2, axis=0)\n",
    "denominator = np.sum((GT_feats - np.mean(GT_feats, axis=0)) ** 2, axis=0) + epsilon\n",
    "r2 = 1 - (numerator / denominator)\n",
    "\n",
    "# Calculating MAE\n",
    "mae = np.mean(np.abs(GT_feats - Y_feats), axis=0)\n",
    "smape = np.mean(np.abs(GT_feats - Y_feats) / (np.abs(GT_feats) + epsilon), axis=0)\n",
    "wmape = np.sum(np.abs(GT_feats - Y_feats), axis=0) / np.sum(np.abs(GT_feats) + epsilon, axis=0)\n",
    "accuracy = np.mean(np.abs(GT_feats - Y_feats) < 0.01 * GT_feats, axis=0)\n",
    "precision = np.mean(np.abs(GT_feats - Y_feats) < 0.01 * GT_feats, axis=0)\n",
    "recall = np.mean(np.abs(GT_feats - Y_feats) < 0.01 * GT_feats, axis=0)\n",
    "f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "df, df_ms2, df_categorical = results_to_df(feature_names, mae, r2, norm_values, smape, wmape, f1, accuracy, precision, recall)\n",
    "\n",
    "#write results to results path:\n",
    "GT_feats = pd.DataFrame(GT_feats, columns=feature_names)\n",
    "Y_feats = pd.DataFrame(Y_feats, columns=feature_names)\n",
    "# os.makedirs(f'{results_path}/unknown_data', exist_ok=True)\n",
    "# #make \"unknown data\" subdirectory\n",
    "GT_feats.to_csv(f'{results_path}/unknown_data/GT_feats.csv')\n",
    "Y_feats.to_csv(f'{results_path}/unknown_data/Y_feats.csv')\n",
    "df.to_csv(f'{results_path}/unknown_data/results.csv')\n",
    "df_ms2.to_csv(f'{results_path}/unknown_data/results_ms2.csv')\n",
    "df_categorical.to_csv(f'{results_path}/unknown_data/results_categorical.csv')\n",
    "df.loc['smape'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
